{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T07:16:21.968711Z",
     "iopub.status.busy": "2023-11-29T07:16:21.968422Z",
     "iopub.status.idle": "2023-11-29T07:16:34.7052Z",
     "shell.execute_reply": "2023-11-29T07:16:34.704218Z",
     "shell.execute_reply.started": "2023-11-29T07:16:21.968685Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T07:16:34.708613Z",
     "iopub.status.busy": "2023-11-29T07:16:34.707407Z",
     "iopub.status.idle": "2023-11-29T07:16:34.716664Z",
     "shell.execute_reply": "2023-11-29T07:16:34.715641Z",
     "shell.execute_reply.started": "2023-11-29T07:16:34.708567Z"
    }
   },
   "outputs": [],
   "source": [
    "if (tf.test.is_gpu_available):\n",
    "    print(\"GPU\")\n",
    "else:\n",
    "    print(\"CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T07:16:34.718726Z",
     "iopub.status.busy": "2023-11-29T07:16:34.718177Z",
     "iopub.status.idle": "2023-11-29T07:16:37.201429Z",
     "shell.execute_reply": "2023-11-29T07:16:37.200311Z",
     "shell.execute_reply.started": "2023-11-29T07:16:34.718574Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T07:16:37.203877Z",
     "iopub.status.busy": "2023-11-29T07:16:37.203588Z",
     "iopub.status.idle": "2023-11-29T07:16:37.214554Z",
     "shell.execute_reply": "2023-11-29T07:16:37.213801Z",
     "shell.execute_reply.started": "2023-11-29T07:16:37.20385Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_dataset(dataset_root):\n",
    "    classes = sorted([cls for cls in os.listdir(dataset_root) if os.path.isdir(os.path.join(dataset_root, cls))])\n",
    "    x = []\n",
    "    y = []\n",
    "    for i, cls in enumerate(classes):\n",
    "        cls_images = sorted(os.listdir(os.path.join(dataset_root, cls)))\n",
    "        x.extend([os.path.join(dataset_root, cls, img) for img in cls_images])\n",
    "        y.extend([i] * len(cls_images))\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T07:16:37.215795Z",
     "iopub.status.busy": "2023-11-29T07:16:37.215521Z",
     "iopub.status.idle": "2023-11-29T07:16:45.151516Z",
     "shell.execute_reply": "2023-11-29T07:16:45.150435Z",
     "shell.execute_reply.started": "2023-11-29T07:16:37.215761Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load your dataset\n",
    "dataset_root = '/kaggle/input/facedatasets'  # Replace with the path to your dataset\n",
    "x, y = load_dataset(dataset_root)\n",
    "\n",
    "# Split the dataset into training, validation, and test sets\n",
    "x_train, x_temp, y_train, y_temp = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_temp, y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T07:16:45.153022Z",
     "iopub.status.busy": "2023-11-29T07:16:45.152699Z",
     "iopub.status.idle": "2023-11-29T07:16:45.159204Z",
     "shell.execute_reply": "2023-11-29T07:16:45.158024Z",
     "shell.execute_reply.started": "2023-11-29T07:16:45.152988Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Number of images:\", len(x))\n",
    "print(\"Some image paths:\", x[:5])\n",
    "print(\"Corresponding labels:\", y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T07:16:45.161674Z",
     "iopub.status.busy": "2023-11-29T07:16:45.161312Z",
     "iopub.status.idle": "2023-11-29T07:16:45.238495Z",
     "shell.execute_reply": "2023-11-29T07:16:45.237451Z",
     "shell.execute_reply.started": "2023-11-29T07:16:45.161638Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_pairs(x, y):\n",
    "    pair_images = []\n",
    "    pair_labels = []\n",
    "\n",
    "    class_indices = dict((c, [i for i, label in enumerate(y) if label == c]) for c in set(y))\n",
    "\n",
    "    for idx, (img_path, label) in enumerate(zip(x, y)):\n",
    "        # Add a positive pair\n",
    "        positive_options = class_indices[label]\n",
    "        if len(positive_options) > 1:  # Ensure there is more than one image in the class\n",
    "            positive_idx = idx\n",
    "            while positive_idx == idx:\n",
    "                positive_idx = random.choice(positive_options)\n",
    "            pair_images.append([img_path, x[positive_idx]])\n",
    "            pair_labels.append(1)\n",
    "\n",
    "        # Add a negative pair\n",
    "        negative_labels = list(set(y) - set([label]))\n",
    "        if negative_labels:  # Ensure there is at least one other class\n",
    "            negative_label = random.choice(negative_labels)\n",
    "            negative_idx = random.choice(class_indices[negative_label])\n",
    "            pair_images.append([img_path, x[negative_idx]])\n",
    "            pair_labels.append(0)\n",
    "\n",
    "    return pair_images, pair_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T07:16:45.241553Z",
     "iopub.status.busy": "2023-11-29T07:16:45.241218Z",
     "iopub.status.idle": "2023-11-29T07:16:47.485635Z",
     "shell.execute_reply": "2023-11-29T07:16:47.484787Z",
     "shell.execute_reply.started": "2023-11-29T07:16:45.241527Z"
    }
   },
   "outputs": [],
   "source": [
    "# make train pairs\n",
    "pairs_train, labels_train = create_pairs(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T07:16:47.487052Z",
     "iopub.status.busy": "2023-11-29T07:16:47.486748Z",
     "iopub.status.idle": "2023-11-29T07:16:47.492084Z",
     "shell.execute_reply": "2023-11-29T07:16:47.491188Z",
     "shell.execute_reply.started": "2023-11-29T07:16:47.487025Z"
    }
   },
   "outputs": [],
   "source": [
    "print(pairs_train[:10], labels_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T07:16:47.496056Z",
     "iopub.status.busy": "2023-11-29T07:16:47.495723Z",
     "iopub.status.idle": "2023-11-29T07:16:47.583318Z",
     "shell.execute_reply": "2023-11-29T07:16:47.582509Z",
     "shell.execute_reply.started": "2023-11-29T07:16:47.496025Z"
    }
   },
   "outputs": [],
   "source": [
    "# make validation pairs\n",
    "pairs_val, labels_val = create_pairs(x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T07:16:47.58456Z",
     "iopub.status.busy": "2023-11-29T07:16:47.584302Z",
     "iopub.status.idle": "2023-11-29T07:16:47.663835Z",
     "shell.execute_reply": "2023-11-29T07:16:47.663031Z",
     "shell.execute_reply.started": "2023-11-29T07:16:47.584537Z"
    }
   },
   "outputs": [],
   "source": [
    "# make test pairs\n",
    "pairs_test, labels_test = create_pairs(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T07:16:47.665321Z",
     "iopub.status.busy": "2023-11-29T07:16:47.665035Z",
     "iopub.status.idle": "2023-11-29T07:16:47.675108Z",
     "shell.execute_reply": "2023-11-29T07:16:47.674122Z",
     "shell.execute_reply.started": "2023-11-29T07:16:47.665295Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "def visualize(pairs, labels, to_show=6, num_col=3, predictions=None, test=False):\n",
    "    \"\"\"Visualizes pairs of images with labels (and predictions, if test dataset).\"\"\"\n",
    "    num_row = to_show // num_col if to_show // num_col != 0 else 1\n",
    "    to_show = num_row * num_col\n",
    "\n",
    "    fig, axes = plt.subplots(num_row, num_col, figsize=(5 * num_col, 5 * num_row))\n",
    "    for i in range(to_show):\n",
    "        if num_row == 1:\n",
    "            ax = axes[i % num_col]\n",
    "        else:\n",
    "            ax = axes[i // num_col, i % num_col]\n",
    "\n",
    "        # Load images\n",
    "        img1 = Image.open(pairs[i][0])\n",
    "        img2 = Image.open(pairs[i][1])\n",
    "\n",
    "        # Concatenate images\n",
    "        combined_img = Image.new('RGB', (img1.width + img2.width, img1.height))\n",
    "        combined_img.paste(img1, (0, 0))\n",
    "        combined_img.paste(img2, (img1.width, 0))\n",
    "\n",
    "        ax.imshow(combined_img)\n",
    "        ax.set_axis_off()\n",
    "\n",
    "        if test:\n",
    "            ax.set_title(\"True: {} | Pred: {:.5f}\".format(labels[i], predictions[i][0]))\n",
    "        else:\n",
    "            ax.set_title(\"Label: {}\".format(labels[i]))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T07:16:47.676562Z",
     "iopub.status.busy": "2023-11-29T07:16:47.676256Z",
     "iopub.status.idle": "2023-11-29T07:16:52.138368Z",
     "shell.execute_reply": "2023-11-29T07:16:52.136797Z",
     "shell.execute_reply.started": "2023-11-29T07:16:47.676536Z"
    }
   },
   "outputs": [],
   "source": [
    "visualize(pairs_train, labels_train, to_show=24, num_col=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T07:16:52.140285Z",
     "iopub.status.busy": "2023-11-29T07:16:52.139929Z",
     "iopub.status.idle": "2023-11-29T07:16:56.783887Z",
     "shell.execute_reply": "2023-11-29T07:16:56.782764Z",
     "shell.execute_reply.started": "2023-11-29T07:16:52.140255Z"
    }
   },
   "outputs": [],
   "source": [
    "visualize(pairs_val, labels_val, to_show=24, num_col=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T07:16:56.785475Z",
     "iopub.status.busy": "2023-11-29T07:16:56.785157Z",
     "iopub.status.idle": "2023-11-29T07:17:01.648262Z",
     "shell.execute_reply": "2023-11-29T07:17:01.647175Z",
     "shell.execute_reply.started": "2023-11-29T07:16:56.785446Z"
    }
   },
   "outputs": [],
   "source": [
    "visualize(pairs_test, labels_test, to_show=24, num_col=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T07:17:01.649851Z",
     "iopub.status.busy": "2023-11-29T07:17:01.649554Z",
     "iopub.status.idle": "2023-11-29T07:17:05.317542Z",
     "shell.execute_reply": "2023-11-29T07:17:05.316485Z",
     "shell.execute_reply.started": "2023-11-29T07:17:01.649825Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, applications, regularizers\n",
    "\n",
    "# Euclidean distance function remains the same\n",
    "def euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    sum_square = tf.math.reduce_sum(tf.math.square(x - y), axis=1, keepdims=True)\n",
    "    return tf.math.sqrt(tf.math.maximum(sum_square, tf.keras.backend.epsilon()))\n",
    "\n",
    "# Modified embedding network using a pre-trained model (e.g., MobileNet)\n",
    "def create_embedding_network(input_shape):\n",
    "    base_model = applications.MobileNetV2(input_shape=input_shape, include_top=False, weights='imagenet', pooling='avg')\n",
    "    \n",
    "    base_model.trainable = True\n",
    "    # Optional: Fine-tuning - freeze layers except the last few\n",
    "    for layer in base_model.layers[:-4]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    model = keras.Sequential([\n",
    "        base_model,\n",
    "        layers.Dense(512, activation=\"relu\"),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(64, activation=\"relu\")\n",
    "    ], name='Embedding')\n",
    "    \n",
    "    return model\n",
    "\n",
    "input_shape = (250, 250, 3)\n",
    "embedding_network = create_embedding_network(input_shape)\n",
    "\n",
    "input_1 = layers.Input(shape=input_shape)\n",
    "input_2 = layers.Input(shape=input_shape)\n",
    "\n",
    "tower_1 = embedding_network(input_1)\n",
    "tower_2 = embedding_network(input_2)\n",
    "\n",
    "merge_layer = layers.Lambda(lambda tensors: tf.math.abs(tensors[0] - tensors[1]))([tower_1, tower_2])\n",
    "output_layer = layers.Dense(1, activation=\"sigmoid\")(merge_layer)\n",
    "\n",
    "siamese = keras.Model(inputs=[input_1, input_2], outputs=output_layer)\n",
    "\n",
    "# Computing the Euclidean distance as output\n",
    "#distance = layers.Lambda(euclidean_distance)([tower_1, tower_2])\n",
    "\n",
    "# Creating the model\n",
    "#siamese = keras.Model(inputs=[input_1, input_2], outputs=distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T07:17:05.319243Z",
     "iopub.status.busy": "2023-11-29T07:17:05.318876Z",
     "iopub.status.idle": "2023-11-29T07:17:05.325738Z",
     "shell.execute_reply": "2023-11-29T07:17:05.324686Z",
     "shell.execute_reply.started": "2023-11-29T07:17:05.319214Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def contrastive_loss(margin=1):\n",
    "    def loss(y_true, y_pred):\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        square_pred = tf.square(y_pred)\n",
    "        margin_square = tf.square(tf.maximum(margin - y_pred, 0))\n",
    "        return tf.reduce_mean((1 - y_true) * square_pred + y_true * margin_square)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T07:17:05.327374Z",
     "iopub.status.busy": "2023-11-29T07:17:05.327031Z",
     "iopub.status.idle": "2023-11-29T07:17:05.340524Z",
     "shell.execute_reply": "2023-11-29T07:17:05.339668Z",
     "shell.execute_reply.started": "2023-11-29T07:17:05.327345Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "\n",
    "def preprocess_image(image_path, target_size=(250, 250)):\n",
    "    \"\"\"Preprocess a single image with augmentation.\"\"\"\n",
    "    image = Image.open(image_path)\n",
    "    image = image.resize(target_size)\n",
    "    image = np.array(image)\n",
    "\n",
    "    # Convert image to a tf.Tensor to use tf.image functions\n",
    "    image = tf.convert_to_tensor(image, dtype=tf.float32)\n",
    "\n",
    "    # Apply a sequence of augmentations\n",
    "    image = tf.image.random_flip_left_right(image)  # Random horizontal flip\n",
    "    image = tf.image.random_flip_up_down(image)     # Random vertical flip\n",
    "    image = tf.image.random_brightness(image, max_delta=0.3)  # Random brightness\n",
    "    image = tf.image.random_contrast(image, lower=0.8, upper=1.2) # Random contrast\n",
    "    image = tf.image.random_saturation(image, lower=0.8, upper=1.2) # Random saturation\n",
    "    image = tf.image.random_hue(image, max_delta=0.1) # Random hue\n",
    "\n",
    "    # Normalize the image to [0, 1]\n",
    "    image = image / 255.0\n",
    "\n",
    "    return image.numpy()  # Convert back to numpy array if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T07:17:05.342226Z",
     "iopub.status.busy": "2023-11-29T07:17:05.341867Z",
     "iopub.status.idle": "2023-11-29T07:17:05.356615Z",
     "shell.execute_reply": "2023-11-29T07:17:05.355732Z",
     "shell.execute_reply.started": "2023-11-29T07:17:05.342198Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def pair_generator(pairs, labels, batch_size):\n",
    "    \"\"\"Generator that yields batches of pairs and their labels.\"\"\"\n",
    "    while True:\n",
    "        batch_pairs = []\n",
    "        batch_labels = []\n",
    "\n",
    "        for _ in range(batch_size):\n",
    "            idx = np.random.randint(0, len(pairs))\n",
    "            pair = pairs[idx]\n",
    "            label = labels[idx]\n",
    "\n",
    "            image1 = preprocess_image(pair[0])\n",
    "            image2 = preprocess_image(pair[1])\n",
    "\n",
    "            batch_pairs.append([image1, image2])\n",
    "            batch_labels.append(label)\n",
    "\n",
    "        # Convert the list of pairs and labels to numpy arrays\n",
    "        batch_pairs_array = [np.array([pair[0] for pair in batch_pairs]), \n",
    "                             np.array([pair[1] for pair in batch_pairs])]\n",
    "        batch_labels_array = np.array(batch_labels).astype('float32')  # Cast labels to float32\n",
    "\n",
    "        yield batch_pairs_array, batch_labels_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T07:17:05.358352Z",
     "iopub.status.busy": "2023-11-29T07:17:05.358022Z",
     "iopub.status.idle": "2023-11-29T07:17:05.423422Z",
     "shell.execute_reply": "2023-11-29T07:17:05.422478Z",
     "shell.execute_reply.started": "2023-11-29T07:17:05.358313Z"
    }
   },
   "outputs": [],
   "source": [
    "siamese.compile(loss=contrastive_loss(margin=1), optimizer=\"RMSprop\", metrics=[\"accuracy\"])\n",
    "siamese.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T07:17:05.425584Z",
     "iopub.status.busy": "2023-11-29T07:17:05.424787Z",
     "iopub.status.idle": "2023-11-29T07:17:05.429856Z",
     "shell.execute_reply": "2023-11-29T07:17:05.428926Z",
     "shell.execute_reply.started": "2023-11-29T07:17:05.425547Z"
    }
   },
   "outputs": [],
   "source": [
    "#siamese.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "#siamese.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T07:17:05.431297Z",
     "iopub.status.busy": "2023-11-29T07:17:05.431024Z",
     "iopub.status.idle": "2023-11-29T07:17:05.644195Z",
     "shell.execute_reply": "2023-11-29T07:17:05.643111Z",
     "shell.execute_reply.started": "2023-11-29T07:17:05.431272Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_model(siamese, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T07:17:05.645954Z",
     "iopub.status.busy": "2023-11-29T07:17:05.645564Z",
     "iopub.status.idle": "2023-11-29T07:17:05.650841Z",
     "shell.execute_reply": "2023-11-29T07:17:05.649996Z",
     "shell.execute_reply.started": "2023-11-29T07:17:05.645919Z"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 50\n",
    "\n",
    "train_generator = pair_generator(pairs_train, labels_train, BATCH_SIZE)\n",
    "validation_generator = pair_generator(pairs_val, labels_val, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-29T07:17:05.652439Z",
     "iopub.status.busy": "2023-11-29T07:17:05.652095Z",
     "iopub.status.idle": "2023-11-29T07:28:36.046396Z",
     "shell.execute_reply": "2023-11-29T07:28:36.044097Z",
     "shell.execute_reply.started": "2023-11-29T07:17:05.652404Z"
    }
   },
   "outputs": [],
   "source": [
    "history = siamese.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(pairs_train) // BATCH_SIZE,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=len(pairs_val) // BATCH_SIZE,\n",
    "    epochs=EPOCHS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_metric(history, metric, title, has_valid=True):\n",
    "    \"\"\"Plots the given 'metric' from 'history'.\n",
    "\n",
    "    Arguments:\n",
    "        history: history attribute of History object returned from Model.fit.\n",
    "        metric: Metric to plot, a string value present as key in 'history'.\n",
    "        title: A string to be used as title of plot.\n",
    "        has_valid: Boolean, true if valid data was passed to Model.fit else false.\n",
    "\n",
    "    Returns:\n",
    "        None.\n",
    "    \"\"\"\n",
    "    plt.plot(history[metric])\n",
    "    if has_valid:\n",
    "        plt.plot(history[\"val_\" + metric])\n",
    "        plt.legend([\"train\", \"validation\"], loc=\"upper left\")\n",
    "    plt.title(title)\n",
    "    plt.ylabel(metric)\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the accuracy\n",
    "plt_metric(history=history.history, metric=\"accuracy\", title=\"Model accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the constrastive loss\n",
    "plt_metric(history=history.history, metric=\"loss\", title=\"Constrastive Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = pair_generator(pairs_test, labels_test, BATCH_SIZE)\n",
    "test_loss, test_accuracy = siamese.evaluate(test_generator, steps=len(pairs_test) // BATCH_SIZE)\n",
    "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Assuming siamese is your Siamese model\n",
    "siamese.save('siamese_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese.save('siamese_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions = siamese.predict([[pairs_test[i][0] for i in range(len(pairs_test))]\n",
    "#                               ,[pairs_test[i][1] for i in range(len(pairs_test))]])\n",
    "#visualize(pairs_test, labels_test, to_show=3, predictions=predictions, test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gg = [pairs_test[i][0] for i in range(len(pairs_test))]\n",
    "#wp = [pairs_test[i][1] for i in range(len(pairs_test))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a batch of pairs\n",
    "#pairs_batch, labels_batch = next(pair_generator(pairs_test, labels_test, batch_size=10))\n",
    "\n",
    "# Predict\n",
    "#predictions = siamese.predict([np.array([pair[0] for pair in pairs_batch]), \n",
    "#                               np.array([pair[1] for pair in pairs_batch])])\n",
    "\n",
    "# Visualize the predictions along with the true labels using the new function\n",
    "#visualize_arrays(pairs_batch, labels_batch, predictions=predictions, to_show=10, num_col=3, test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a batch of pairs\n",
    "#pairs_batch, labels_batch = next(pair_generator(pairs_test, labels_test, batch_size=1))\n",
    "\n",
    "# Predict\n",
    "#predictions = siamese.predict(pairs_batch)\n",
    "\n",
    "# Optionally: perform further analysis, visualize results, calculate additional metrics, etc.\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4072792,
     "sourceId": 7072012,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30588,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
